"use strict";(self.webpackChunkreubenliengaard_github_io=self.webpackChunkreubenliengaard_github_io||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"manchester-pride","metadata":{"permalink":"/blog/manchester-pride","editUrl":"https://github.com/reubenliengaard/blog/2020-01-02-MP2020-ruckus-wireless-heatmap.md","source":"@site/blog/2020-01-02-MP2020-ruckus-wireless-heatmap.md","title":"Manchester Pride - Ruckus wireless heatmap","description":"During this deployment, we faced a physically challenging task. We mounted two sectors on the 18th floor of a tower block that was next to the site. From there, we transmitted the signal to multiple wireless point-to-point stations that were attached to temporary structures and buildings within the site. We also provided indoor wireless coverage in an underground parking garage that was used as one of the event venues. I created a heat map of the wireless signal strength in this area. In addition, we established uplinks at various locations to support ticket booths, CCTV cameras, payment terminals for bars, a production office, and emergency liaison cabins.","date":"2020-01-02T00:00:00.000Z","formattedDate":"January 2, 2020","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.535,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"manchester-pride","title":"Manchester Pride - Ruckus wireless heatmap","authors":"reubenliengaard","tags":["hola","docusaurus"]},"nextItem":{"title":"Royal Windsor Horse Show - Ruckus wireless heatmap","permalink":"/blog/windsor-horse-show"}},"content":"During this deployment, we faced a physically challenging task. We mounted two sectors on the 18th floor of a tower block that was next to the site. From there, we transmitted the signal to multiple wireless point-to-point stations that were attached to temporary structures and buildings within the site. We also provided indoor wireless coverage in an underground parking garage that was used as one of the event venues. I created a heat map of the wireless signal strength in this area. In addition, we established uplinks at various locations to support ticket booths, CCTV cameras, payment terminals for bars, a production office, and emergency liaison cabins."},{"id":"windsor-horse-show","metadata":{"permalink":"/blog/windsor-horse-show","editUrl":"https://github.com/reubenliengaard/blog/2019-07-21-WHS2018-ruckus-wireless-heatmap.md","source":"@site/blog/2019-07-21-WHS2018-ruckus-wireless-heatmap.md","title":"Royal Windsor Horse Show - Ruckus wireless heatmap","description":"The Royal Windsor Horse Show is the largest outdoor horse show in the UK. We provided connectivity to the staff and trader areas. After deployment, a wireless heat map was created by extensively taking geolocated signal strength readings on a smartphone from all over the site. This data was uploaded into ArcGIS and used to create a heat map, which highlighted areas with weak signal strength or wireless black spots. This heat map was overlaid on a georeferenced site map, with the locations of wireless access points, cable routes, and network switch locations marked.","date":"2019-07-21T00:00:00.000Z","formattedDate":"July 21, 2019","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.47,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"windsor-horse-show","title":"Royal Windsor Horse Show - Ruckus wireless heatmap","authors":"reubenliengaard","tags":["hola","docusaurus"]},"prevItem":{"title":"Manchester Pride - Ruckus wireless heatmap","permalink":"/blog/manchester-pride"},"nextItem":{"title":"Live network status map for WOMAD 2020","permalink":"/blog/womad"}},"content":"The Royal Windsor Horse Show is the largest outdoor horse show in the UK. We provided connectivity to the staff and trader areas. After deployment, a wireless heat map was created by extensively taking geolocated signal strength readings on a smartphone from all over the site. This data was uploaded into ArcGIS and used to create a heat map, which highlighted areas with weak signal strength or wireless black spots. This heat map was overlaid on a georeferenced site map, with the locations of wireless access points, cable routes, and network switch locations marked."},{"id":"womad","metadata":{"permalink":"/blog/womad","editUrl":"https://github.com/reubenliengaard/blog/2019-05-29-WOMAD2020-live-network-status-map.md","source":"@site/blog/2019-05-29-WOMAD2020-live-network-status-map.md","title":"Live network status map for WOMAD 2020","description":"","date":"2019-05-29T00:00:00.000Z","formattedDate":"May 29, 2019","tags":[{"label":"hello","permalink":"/blog/tags/hello"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"womad","title":"Live network status map for WOMAD 2020","authors":"reubenliengaard","tags":["hello","docusaurus"]},"prevItem":{"title":"Royal Windsor Horse Show - Ruckus wireless heatmap","permalink":"/blog/windsor-horse-show"},"nextItem":{"title":"Identify areas of flat terrain which receive the most sun","permalink":"/blog/flat-sunny-spots"}},"content":""},{"id":"flat-sunny-spots","metadata":{"permalink":"/blog/flat-sunny-spots","editUrl":"https://github.com/reubenliengaard/blog/2019-05-29-flat-sunny-spots.md","source":"@site/blog/2019-05-29-flat-sunny-spots.md","title":"Identify areas of flat terrain which receive the most sun","description":"","date":"2019-05-29T00:00:00.000Z","formattedDate":"May 29, 2019","tags":[{"label":"hello","permalink":"/blog/tags/hello"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"flat-sunny-spots","title":"Identify areas of flat terrain which receive the most sun","authors":"reubenliengaard","tags":["hello","docusaurus"]},"prevItem":{"title":"Live network status map for WOMAD 2020","permalink":"/blog/womad"},"nextItem":{"title":"Bath Festival - Ruckus wireless heatmap","permalink":"/blog/bath-festival"}},"content":""},{"id":"bath-festival","metadata":{"permalink":"/blog/bath-festival","editUrl":"https://github.com/reubenliengaard/blog/2018-04-18-BF2018-ruckus-wireless-heatmap .md","source":"@site/blog/2018-04-18-BF2018-ruckus-wireless-heatmap .md","title":"Bath Festival - Ruckus wireless heatmap","description":"A small deployment of Ruckus R600 access points was placed around the tents at the Bath Festival. Each access point was connected to a sector on an adjacent building via a point-to-point wireless link, connected to both a ADSL line and a temporary satellite on the roof. Using an Android app, I collected a series of geolocated signal strength data points and formatted them in Excel. This data was then uploaded into ArcGIS, where a tool was used to create a heat map, which was overlayed over the site plan.","date":"2018-04-18T00:00:00.000Z","formattedDate":"April 18, 2018","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.45,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"bath-festival","title":"Bath Festival - Ruckus wireless heatmap","authors":"reubenliengaard","tags":["hola","docusaurus"]},"prevItem":{"title":"Identify areas of flat terrain which receive the most sun","permalink":"/blog/flat-sunny-spots"},"nextItem":{"title":"AONB Permitted Development","permalink":"/blog/aonb-permitted-development"}},"content":"A small deployment of Ruckus R600 access points was placed around the tents at the Bath Festival. Each access point was connected to a sector on an adjacent building via a point-to-point wireless link, connected to both a ADSL line and a temporary satellite on the roof. Using an Android app, I collected a series of geolocated signal strength data points and formatted them in Excel. This data was then uploaded into ArcGIS, where a tool was used to create a heat map, which was overlayed over the site plan."},{"id":"aonb-permitted-development","metadata":{"permalink":"/blog/aonb-permitted-development","editUrl":"https://github.com/reubenliengaard/blog/2018-04-18-aonb-permitted-development.md","source":"@site/blog/2018-04-18-aonb-permitted-development.md","title":"AONB Permitted Development","description":"","date":"2018-04-18T00:00:00.000Z","formattedDate":"April 18, 2018","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"aonb-permitted-development","title":"AONB Permitted Development","authors":"reubenliengaard","tags":["hola","docusaurus"]},"prevItem":{"title":"Bath Festival - Ruckus wireless heatmap","permalink":"/blog/bath-festival"},"nextItem":{"title":"Flood risk analasis for pudding brooke","permalink":"/blog/pudding-brook"}},"content":""},{"id":"pudding-brook","metadata":{"permalink":"/blog/pudding-brook","editUrl":"https://github.com/reubenliengaard/blog/2017-05-22-flood-risk-analasis-of-pudding-brook.md","source":"@site/blog/2017-05-22-flood-risk-analasis-of-pudding-brook.md","title":"Flood risk analasis for pudding brooke","description":"Digital Terrain Model LIDAR tiles were imported into QGIS and used to create contour polygons at 2m intervals. A graduated style was applied to color the polygons by their elevation. Potential sites for outbuildings were then selected in appropriate high ground locations.","date":"2017-05-22T00:00:00.000Z","formattedDate":"May 22, 2017","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.21,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"pudding-brook","title":"Flood risk analasis for pudding brooke","authors":"reubenliengaard","tags":["hola","docusaurus"]},"prevItem":{"title":"AONB Permitted Development","permalink":"/blog/aonb-permitted-development"},"nextItem":{"title":"House prices paid by parish","permalink":"/blog/house-price-paid-parish"}},"content":"Digital Terrain Model LIDAR tiles were imported into QGIS and used to create contour polygons at 2m intervals. A graduated style was applied to color the polygons by their elevation. Potential sites for outbuildings were then selected in appropriate high ground locations."},{"id":"house-price-paid-parish","metadata":{"permalink":"/blog/house-price-paid-parish","editUrl":"https://github.com/reubenliengaard/blog/20121-07-14-house-prices-paid-by-parish/index.md","source":"@site/blog/20121-07-14-house-prices-paid-by-parish/index.md","title":"House prices paid by parish","description":"To obtain the latitude and longitude positions of each house sale value, the house price paid postcodes from the land registry were cross-referenced with OS code point data. The UK parish data was then uploaded to PostGIS, and an SQL query was used to calculate the average price within each parish. This information was imported into QGIS and used to apply a style to the parish polygons based on the average value.","date":"0121-07-14T00:00:00.000Z","formattedDate":"July 14, 121","tags":[{"label":"hello","permalink":"/blog/tags/hello"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":1.885,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"house-price-paid-parish","title":"House prices paid by parish","authors":"reubenliengaard","tags":["hello","docusaurus"]},"prevItem":{"title":"Flood risk analasis for pudding brooke","permalink":"/blog/pudding-brook"},"nextItem":{"title":"House prices paid parcels","permalink":"/blog/house-price-parcels"}},"content":"To obtain the latitude and longitude positions of each house sale value, the house price paid postcodes from the land registry were cross-referenced with OS code point data. The UK parish data was then uploaded to PostGIS, and an SQL query was used to calculate the average price within each parish. This information was imported into QGIS and used to apply a style to the parish polygons based on the average value.\\n\\n\\n![alt text](./house-price-parish.jpg \\"Price Paid Style\\")\\n\\n# Average Price Paid Parish\\n\\n## Download data\\n\\nDonloading a csv file of property price paid data for each of the last three years, postcode coordinates, and\\nboundry line polygons.\\n\\n```\\n$ wget bdline_gpkg_gb.zip\\n&& unzip bdline_gpkg_gb.zip\\n&& cd data\\n```\\n## Import bdline\\n\\nUsing ogr2ogr to convert the boundry line GeoPackage file into PostgreSQL file, reprojecting it from\\nOSGB1936 to WGS84, and importing it into the database.\\n\\n```\\nogr2ogr \\\\\\n-f \\"PostgreSQL\\" \\\\\\n-a_srs \\"EPSG:27700\\" \\\\\\n```\\n\\n```\\n-t_srs \\"EPSG:4326\\" \\\\\\n-progress PG:\\"dbname=\'gis\' host=\'$ip\' port=\'5432\' user=\'$user\'\\npassword=\'$password\'\\" \\\\\\nbdline_gb.gpkg\\n```\\n## Connect to server\\n\\nStarting a psql instance on the client in order to interact with the database on the server.\\n\\n```\\npsql -h 192.168.88.10 -U postgres gis\\n```\\n# Create priced paid polygons for every point\\n\\nUsing the point data already present in the database from the previous project to create a duplicate\\npolygon from the parish geometry table for every point each polygon contains, and appending the point\\nprice paid to it.\\n\\n### SELECT\\n\\n```\\nparish.geom,\\npoints.pounds\\nINTO pp_parish\\nFROM\\nparish INNER JOIN points\\nON st_contains(parish.geom, points.geom);\\n```\\n## Find avarage point value for duplicate polygons\\n\\nAs in the previous project, avaraging the values of the duplicate polygons back one.\\n\\n```\\nSELECT geom,avg(pounds)\\nINTO avg_pp_parish\\nFROM pp_parish\\nGROUP BY geom;\\n```\\n## Import new price paid polygons to file\\n\\n```\\nQgis > Database > DB Manager > Import Layer/File - Name: pp_parish\\n```\\n## Add price paid polygons layer to Qgis\\n\\n```\\nQgis > Layer > Add Layer > Add Vector Layer\\nQgis > Database > DB Manager > Import Layer/File - Name: pp_parish\\nVector Dataset(s): .shp\\n```\\n\\n## Colour polygons by attribute field\\n\\n```\\nRight click: Layer > Properties\\nSymbology > Single Symbol: Gradiated\\nVaule: pounds\\nColour Ramp: Spectral\\nInvert Colour Ramp\\nSegmentation: Equal Interval\\n```"},{"id":"house-price-parcels","metadata":{"permalink":"/blog/house-price-parcels","editUrl":"https://github.com/reubenliengaard/blog/20121-07-13-house-prices-paid-by-parcels.md","source":"@site/blog/20121-07-13-house-prices-paid-by-parcels.md","title":"House prices paid parcels","description":"Prepare prices data","date":"0121-07-13T00:00:00.000Z","formattedDate":"July 13, 121","tags":[{"label":"hello","permalink":"/blog/tags/hello"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":3.525,"hasTruncateMarker":false,"authors":[{"name":"Reuben Liengaard","title":"Maintainer","url":"https://reubenliengaard.github.io","key":"reubenliengaard"}],"frontMatter":{"slug":"house-price-parcels","title":"House prices paid parcels","authors":"reubenliengaard","tags":["hello","docusaurus"]},"prevItem":{"title":"House prices paid by parish","permalink":"/blog/house-price-paid-parish"}},"content":"## Prepare prices data\\n\\nConcatenating the three price paid files together into one file, removing unnecessary field quotes,\\nselecting only rows which contain the string GL followed by a number between zero and nine, then printing\\nout only columns four and two, adding column names, then deleting rows containing null values.\\n\\n```\\n$ cat pp-2018.csv pp-2019.csv pp-2020.csv | tr -d \'\\"\' > pp_3year.csv \\\\\\n&& awk -F\\",\\" \'/GL+[0-9]/ { print $4 \\",\\" $2}\' pp_3year.csv > gl_p_3.csv \\\\\\n&& { echo \\"postcode, pounds\\"; cat gl_p_3.csv; } > prices.csv \\\\\\n&& sed -i \'/\\\\\\\\N/d\' prices.csv\\n```\\n## Prepare location data\\n\\nApplying the same process as for the price data, minus the concatenation.\\n\\n```\\n$ awk -F\\",\\" \'/GL+[0-9]/ { print $1 \\",\\" $8 \\",\\" $9}\' open_postcode_geo.csv >\\ngl_l.csv \\\\\\n&& { echo \\"postcode, latitude, longitude\\"; cat gl_l.csv; } >\\ncoordinates.csv \\\\\\n&& sed -i \'/\\\\\\\\N/d\' coordinates.csv\\n```\\n## Import parcels\\n\\n\\nUsing ogr2ogr to convert the cadastral parcels GML file into PostgreSQL file, projecting it from OSGB\\nto WGS84, and importing it into the database.\\n\\n```\\nogr2ogr \\\\\\n-f \\"PostgreSQL\\" \\\\\\n-a_srs \\"EPSG:27700\\" \\\\\\n-t_srs \\"EPSG:4326\\" \\\\\\n-nln parcels \\\\\\n-progress \\\\\\nPG:\\"dbname=\'gis\' host=\'$ip\' port=\'5432\' user=\'$user\'\\npassword=\'$password\'\\" \\\\\\nLand_Registry_Cadastral_Parcels.gml\\n```\\n## Connect to server\\n\\nStarting a psql instance on the client in order to interact with the database on the server.\\n\\n```\\npsql -h 192.168.88.10 -U postgres gis\\n```\\n## Create prices table\\n\\nCreating a new empty table, with an auto incrementing primary key of type serial, and text and integer\\ncolumns for postcodes and pounds respectively.\\n\\n```\\nCREATE TABLE prices (\\np_prices_id serial PRIMARY KEY,\\np_postcode TEXT NOT NULL,\\npounds INTEGER NOT NULL\\n);\\n```\\n## Create location table\\n\\nCreating a similar empty table for locations, but with latitude, and longitude columns rather instead of a\\npounds column.\\n\\n```\\nCREATE TABLE coordinates (\\nc_id serial PRIMARY KEY,\\nc_postcode TEXT NOT NULL,\\nlatitude FLOAT NOT NULL,\\nlongitude FLOAT NOT NULL\\n);\\n```\\n## Populate prices table\\n\\n\\nImporting the prices data into the new price column using the \\\\copy command in psql.\\n\\n```\\n\\\\copy prices(p_postcode, pounds) FROM \'/home/reuben/Downloads/prices.csv\'\\nDELIMITER \',\' CSV HEADER;\\n```\\n## Populate coordinates table\\n\\nRepeating the process for the coordinates data.\\n\\n```\\n\\\\copy coordinates(c_postcode, latitude, longitude) FROM\\n\'/home/reuben/Downloads/coordinates.csv\' DELIMITER \',\' CSV HEADER;\\n```\\n# Join coordinates and prices into points\\n\\nUsing the SQL join command to make a new table containing the prices and coordinates which share the\\nsame postcode.\\n\\n### SELECT\\n\\n```\\nc_id,\\nc_postcode,\\nlatitude,\\nlongitude,\\npounds\\nINTO points\\nFROM coordinates INNER JOIN prices\\nON coordinates.c_postcode = prices.p_postcode;\\n```\\n# Add geometry column to points\\n\\nAdding an geometry column to the new table.\\n\\n```\\nALTER TABLE points ADD COLUMN geom GEOMETRY(Point, 4326 );\\n```\\n# Update points from coordinates\\n\\nPopulating the geometry column with points created using the contents of the latitude and longitude\\ncolumns.\\n\\n\\n```\\nUPDATE points SET geom = ST_SETSRID(ST_MakePoint(longitude,\\nlatitude), 4326 );\\n```\\n# Create priced polygons\\n\\nCreating a duplicate polygon for every point it contains, and appending the point price paid to it.\\n\\n### SELECT\\n\\n```\\nc_id,\\nparcels.wkb_geometry,\\npoints.pounds\\nINTO polygons\\nFROM\\nparcels INNER JOIN points\\nON st_contains(parcels.wkb_geometry, points.geom);\\n```\\n## Find avarage point value for duplicate polygons\\n\\nAvaraging the values of the duplicate polygons into one. I\'m sure there must be a more efficient way of\\ndoing this with less steps, I will have to look into it.\\n\\n```\\nSELECT c_id,geom,avg(pounds)\\nINTO avg_polygons\\nFROM polygons\\nGROUP BY geom;\\n```\\n## Import new price paid polygons to file\\n\\nUsing Qgis to export the table from the database.\\n\\n```\\nQgis > Database > DB Manager > Import Layer/File - Name: avg_polygons\\n```\\n## Add price paid polygons layer to Qgis\\n\\nDisplaying the layer in Qgis.\\n\\n```\\nQgis > Layer > Add Layer > Add Vector Layer\\nQgis > Database > DB Manager > Import Layer/File - Name: avg_polygons\\nVector Dataset(s): .shp\\n```\\n## Colour polygons by attribute field\\n\\nTweaking the layer properties in order to create a nice visual effect.\\n\\n```\\nRight click: Layer > Properties\\n```\\n\\n```\\nSymbology > Single Symbol: Graduated\\nValue: pounds\\nColour Ramp: Spectral\\nInvert Colour Ramp\\nSegmentation: Equal Interval\\n```\\nI think that some of the postcodes have fallen outside of their intended polygons, for the next project I will\\nuse a set of polygons with less resolution."}]}')}}]);